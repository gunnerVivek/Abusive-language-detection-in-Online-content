{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Purpose of this Notebook</center>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Purpose of this Notebook\n",
    "\n",
    "In this Notebook we perform an initial eyeball exploration of the datasets to find cleaning steps that might be particular to the individual datsets only (does not include generall cleaning steps like mentions, hashtags, punctuation removal, etc).\n",
    "\n",
    "This helps to reduce computing cost instead of brute forcing the same cleaning steps for all of the combined data sources. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 700)\n",
    "#('MAX_COL_WIDTH', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Book Hate Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb = pd.read_csv(\"transformed_data/facebook_hate_speech_translated.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the duplicates\n",
    "fb = fb.drop_duplicates(subset=['translated_message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "abuse       663\n",
       "no_abuse      1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fb.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observe\n",
    "To find the nuances of this dataset we will observe the dataset by sampling it multiple times.\n",
    "\n",
    "Remove:\n",
    "- &quot;\n",
    "- &#39;(unicode in dataset)  with '. In fact remove all decimal encoded puctuation marks with the actual punctuation marks.\n",
    "- @ 137c9c6970afb7fc\n",
    "- repeating !!!\n",
    "\n",
    "\n",
    "Note:\n",
    "- remove accented characters\n",
    "- URL\n",
    "\n",
    "[^a-zA-Z_\\.\\s,] --> Unnecessary characters could be removed. All characters except alphabets, full stop, unsderscore, comma and white space.\n",
    "Multiple white spaces by one white space.\n",
    "\n",
    "\n",
    "Each sentence of the document should be predicted and then if any of the sentences are abusive, whole document should be classified as abusive.\n",
    "Also highlight the abusive part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps for cleaning\n",
    "\n",
    "- puctuation marks correction\n",
    "- Mentions, Hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CLARIFICATION TO COVER UP THE REASONS FOR THE GOODS, BY THE LIES POLICY and YOUR LIES MEDIA, FOR PEGIDA '"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = fb.loc[643,'translated_message']\n",
    "re.sub(\"[^a-zA-Z_\\.\\s,]\",'', x) # remove all special characters and numbers\n",
    "re.sub(r\"\\b(([a-z]+\\d+)|(\\d+[a-z]+))(\\w)+\\b\", '', x) # 02ab63aad79877f5, ab63aad79877f5, 3f3g6hj7j5v and fg54jkk098ui\n",
    "\n",
    "# re.sub(\"&#39;\", \"'\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['33']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "re.findall(\"\\d+\", ''.join(re.findall(\"&#\\d+;\", \"Hello &#33;\")))\n",
    "\n",
    "# re.findall(\"\\d+\", \"&#33;\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@  what&#39;s so bad about being put to the right so I always openly say my opinion about these shit foreigners I don&#39;t care what the others think or say and I think that should do a lot more otherwise the state never ends what there is much too few neo-nazis say your opinion openly, these shit shit should get out of our country !!!!!!!'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = fb.translated_message.loc[56]\n",
    "re.sub(r\"\\b(([a-z]+\\d+)|(\\d+[a-z]+))(\\w)+\\b\", '', x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also remove sentences that are abusive only in specific context. We want a generalised system.\n",
    "\n",
    "Remove :\n",
    "0, 9, 10, 13, 18, 31, 34, 35, 39, 41, 52, 55, 59, 69, 70, 72, 73, 78, 101, 103, 107, 116, 117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_rows = [0, 9, 10, 13, 18, 31, 34, 35, 39, 41, 52, 55, 59, 69, 70, 72, 73, 78, 101, 103, 107, 116, 117]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(641, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fb.drop(index=delete_rows).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikipedia Personal Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki = pd.read_csv(\"transformed_data/wikipedia_personal_attacks.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115864, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki = wiki.drop_duplicates(subset=['comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no_abuse    100142\n",
       "abuse        15563\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Statement I would like to be unblocked please, my actions four years ago were unwarranted and I apologise, I would like to contribute constructively.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg = \"NEWLINE_TOKENNEWLINE_TOKEN== Statement ==NEWLINE_TOKENI would like to be unblocked please, my actions four years ago were unwarranted and I apologise, I would like to contribute constructively.\"\n",
    "re.sub(\"[^a-zA-Z_\\.\\s,]\", \"\", re.sub(r\"NEWLINE_TOKEN\", \"\", msg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations\n",
    "Remove:\n",
    "- NEWLINE_TOKEN\n",
    "- ``.*`` indicates quotes\n",
    "- (UTC)\n",
    "\n",
    "Notes:\n",
    "- remove accented characters\n",
    "- u with you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# White Supremist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_s = pd.read_csv(\"transformed_data/white_supremist_data.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Shape: (10703, 2)\n",
      "After Duplicate removal: (10534, 2)\n"
     ]
    }
   ],
   "source": [
    "print('Original Shape: {0}'.format(w_s.shape))\n",
    "print('After Duplicate removal:', w_s.drop_duplicates(subset=['text']).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no_abuse    9507\n",
       "abuse       1196\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_s.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations\n",
    "\n",
    "- \"[....]\" | '[....]' : every document is a list element.\n",
    "\n",
    "\n",
    "Notes:\n",
    "n't --> not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I 'm surprised Greek or some Asiatic languages did n't pop up .\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x = ''.join(w_s.text.loc[[6310, 2334]].values)\n",
    "x = ''.join(w_s.text.loc[6310])\n",
    "# re.sub('([(\\\"|\\')).*((\\\"|\\')])', \"\", x)\n",
    "# ''.join(re.sub('''(\"|')\\]''', \"\", re.sub('''\\[(\"|')''', \"\", x)))\n",
    "# x\n",
    "x.replace('[\"', '').replace('\"]', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetr = pd.read_csv(\"transformed_data/tweeter_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet', 'label'], dtype='object')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Shape: (67079, 2)\n",
      "After Duplicate removal: (20484, 2)\n"
     ]
    }
   ],
   "source": [
    "print('Original Shape: {0}'.format(tweetr.shape))\n",
    "print('After Duplicate removal:', tweetr.drop_duplicates(subset=['tweet']).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetr = tweetr.drop_duplicates(subset=['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['label', 'abuse'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetr.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20483, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetr = tweetr.drop(index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation\n",
    "\n",
    "Remove:\n",
    "\n",
    "- RT\n",
    "\n",
    "NOte:\n",
    "- emoji &#9825; &#128166; &#128540; --> &#\\d+;\n",
    "- &#8220; &#128526;&#8221;\n",
    "- Emojis have similar regex compared to apostrophe. Hence they must be removed only after apostrophe substitution.\n",
    "Column name change in combined data. Data in DB already has same column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @TrillAssKass: wet pussy makes the dick slip out '"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tweetr.tweet.loc[14721]\n",
    "\n",
    "re.sub(\"&#\\d+;\", \"\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tweetr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toxic Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic = pd.read_csv(\"transformed_data/toxic_comments.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['comment_text', 'label'], dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of original data: (2223063, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of original data:\", toxic.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic = toxic.drop_duplicates(subset=['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after duplicate removal: (2195400, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape after duplicate removal:\", toxic.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['no_abuse', 'abuse'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic.label.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation\n",
    "\n",
    "Remove:\n",
    "\n",
    "- \\n \\r\n",
    "- dawggg\n",
    "\n",
    "Note:\n",
    "\n",
    "- 50% -> fifty percent : Eg: Rihanna is 50% black. Her mother is also mixed race, not black."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are the one who recently claimed an assistant professor at the UO makes $200k and then \"looked it up\" and found assistant profs at the UO make $113k. Both were very wrong. You are in no position to claim anyone else is writing fantasy or not when you make such wild statements without support.'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = toxic.comment_text.loc[377713]# 1839087\n",
    "\n",
    "# x.replace(\"\\n\", '')\n",
    "x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
